{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Collaborative filtering in recommender systems</div>\n",
    "\n",
    "1. [Introduction](#sec1)\n",
    "    1. [Recommender systems](#sec1-1)\n",
    "    2. [MovieLens dataset](#sec1-2)\n",
    "2. [Building a recommender system](#sec2)\n",
    "    1. [Nearest Neighborhood algorithm](#sec2-1)\n",
    "    2. [Similarity metrics](#sec2-2)\n",
    "3. [Improving the model](#sec3)\n",
    "    1. [Non-negative Matrix Factorization](#sec3-1)\n",
    "    2. [A working recommender system](#sec3-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import timeit\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec1\"></a> 1. Introduction\n",
    "\n",
    "## <a id=\"sec1-1\"></a> 1.1 Recommender systems\n",
    "\n",
    "A recommendation system is an information filtering system that seeks to predict the \"rating\" or \"preference\" a user would give to an item. It is widely used in different online business such as Amazon, Netflix, Spotify, or social media like Facebook and Youtube. By using recommender systems, those companies are able to provide better or more suited products/services/contents that are personalized to a user based on his historical behavior.\n",
    "\n",
    "Research on recommender algorithms garnered significant attention in 2006 when Netflix launched the Netflix Prize to improve the state of movie recommendation. The objective of this competition was to build a recommender algorithm that could beat their internal CineMatch algorithm in offline tests by 10%. It sparked an intense activity, both in academia and amongst hobbyists. The $1 M prize demonstrates the value that vendors place on accurate recommendations.\n",
    "\n",
    "<img src=\"img/Homer.png\" width=\"500px\">\n",
    "<i>Source: <a>https://medium.com/tiket-com-dev-team/build-recommendation-engine-using-graph-cbd6d8732e46\n",
    "</a></i>\n",
    "<br><br>\n",
    "\n",
    "To build a recommender system, the most two popular approaches are Content-based and Collaborative Filtering.<br><br>\n",
    "The Content-based approach will consist of learning the user's behavior from external information which are provided on the users (like their age, country of residence, ...) and on the items (like in the case of movies: genre, director, year, ...).<br><br>\n",
    "Collaborative Filtering, on the other hand, doesn’t need anything else except users’ historical preference on a set of items. Because it’s based on historical data, the core assumption here is that the users who have agreed in the past tend to also agree in the future.\n",
    "<br><br>\n",
    "In the following document, we focus exclusively on this second approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sec1-2\"></a> 1.2 The MovieLens dataset\n",
    "<br>\n",
    "We choose to use a public dataset from the MovieLens web site (<a>http://movielens.org</a>) made available by GroupLens Research. These files contain 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users who joined MovieLens in 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('data/ml-1m/movies.dat',sep='::',header=None)\n",
    "df_movies.columns = ['movie_id', 'title', 'genre']\n",
    "df_movies.movie_id = df_movies.movie_id - 1\n",
    "\n",
    "df_users = pd.read_csv('data/ml-1m/users.dat',sep='::',header=None)\n",
    "df_users.columns = ['user_id', 'gender', 'age','occupation','zipcode']\n",
    "df_users.user_id = df_users.user_id - 1\n",
    "\n",
    "df = pd.read_csv('data/ml-1m/ratings.dat',sep='::',header=None)\n",
    "df.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "df.movie_id = df.movie_id - 1\n",
    "df.user_id = df.user_id - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of three files:\n",
    "- The first contains information on users: gender, age, occupation and zipcode.\n",
    "- The second contains information on movies: title, year and genre.\n",
    "- The third contains the ratings, represented by an integer value from 1 to 5, with the timestamp of when it was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2159</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>46556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>3678</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>68108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>3892</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>79401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>2419</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>37938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>02151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>5694</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>21221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>3811</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>78749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>51537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>4787</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>85331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>01609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id gender  age  occupation zipcode\n",
       "2159     2159      F   18          19   46556\n",
       "3678     3678      M   25           4   68108\n",
       "3892     3892      M   25           6   79401\n",
       "2419     2419      M   50           7   37938\n",
       "1065     1065      M   45          12   02151\n",
       "5694     5694      F   35           3   21221\n",
       "3811     3811      M   35          17   78749\n",
       "152       152      M    1          10   51537\n",
       "4787     4787      M   35           7   85331\n",
       "24         24      M   18           4   01609"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>885</td>\n",
       "      <td>Bulletproof (1996)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>3430</td>\n",
       "      <td>Death Wish II (1982)</td>\n",
       "      <td>Action|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>Seven (Se7en) (1995)</td>\n",
       "      <td>Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1066</td>\n",
       "      <td>Damsel in Distress, A (1937)</td>\n",
       "      <td>Comedy|Musical|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>Boomerang (1992)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1848</td>\n",
       "      <td>Prince Valiant (1997)</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>490</td>\n",
       "      <td>Man Without a Face, The (1993)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>2291</td>\n",
       "      <td>Overnight Delivery (1996)</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1938</td>\n",
       "      <td>Best Years of Our Lives, The (1946)</td>\n",
       "      <td>Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>2127</td>\n",
       "      <td>Safe Men (1998)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id                                title                   genre\n",
       "874        885                   Bulletproof (1996)                  Action\n",
       "3362      3430                 Death Wish II (1982)            Action|Drama\n",
       "46          46                 Seven (Se7en) (1995)          Crime|Thriller\n",
       "1053      1066         Damsel in Distress, A (1937)  Comedy|Musical|Romance\n",
       "120        121                     Boomerang (1992)          Comedy|Romance\n",
       "1780      1848                Prince Valiant (1997)               Adventure\n",
       "487        490       Man Without a Face, The (1993)                   Drama\n",
       "2223      2291            Overnight Delivery (1996)                 Romance\n",
       "1870      1938  Best Years of Our Lives, The (1946)               Drama|War\n",
       "2059      2127                      Safe Men (1998)                  Comedy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>801381</th>\n",
       "      <td>4801</td>\n",
       "      <td>3825</td>\n",
       "      <td>3</td>\n",
       "      <td>995719068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657209</th>\n",
       "      <td>3960</td>\n",
       "      <td>1982</td>\n",
       "      <td>3</td>\n",
       "      <td>967227560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549032</th>\n",
       "      <td>3388</td>\n",
       "      <td>647</td>\n",
       "      <td>3</td>\n",
       "      <td>967515695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13889</th>\n",
       "      <td>110</td>\n",
       "      <td>2027</td>\n",
       "      <td>5</td>\n",
       "      <td>977511594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649311</th>\n",
       "      <td>3912</td>\n",
       "      <td>1887</td>\n",
       "      <td>3</td>\n",
       "      <td>965766227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985497</th>\n",
       "      <td>5953</td>\n",
       "      <td>2142</td>\n",
       "      <td>1</td>\n",
       "      <td>957651428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560807</th>\n",
       "      <td>3449</td>\n",
       "      <td>3254</td>\n",
       "      <td>3</td>\n",
       "      <td>967244085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939931</th>\n",
       "      <td>5674</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>958685254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95444</th>\n",
       "      <td>638</td>\n",
       "      <td>1196</td>\n",
       "      <td>2</td>\n",
       "      <td>981088461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655493</th>\n",
       "      <td>3947</td>\n",
       "      <td>1277</td>\n",
       "      <td>5</td>\n",
       "      <td>965682239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating  timestamp\n",
       "801381     4801      3825       3  995719068\n",
       "657209     3960      1982       3  967227560\n",
       "549032     3388       647       3  967515695\n",
       "13889       110      2027       5  977511594\n",
       "649311     3912      1887       3  965766227\n",
       "985497     5953      2142       1  957651428\n",
       "560807     3449      3254       3  967244085\n",
       "939931     5674      1502       2  958685254\n",
       "95444       638      1196       2  981088461\n",
       "655493     3947      1277       5  965682239"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct users: 6040\n",
      "Distinct movies: 3952\n"
     ]
    }
   ],
   "source": [
    "nb_users = max(df.user_id.unique()+1)\n",
    "nb_movies = max(df.movie_id.unique()+1)\n",
    "print(\"Distinct users:\",nb_users)\n",
    "print(\"Distinct movies:\",nb_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a recommender system, we first have to convert the ratings' dataframe into a matrix in which each row represents all the ratings made by a user.\n",
    "<br><br>\n",
    "This step can take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [ 3. nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "rating_matrix = np.empty([nb_users,nb_movies])\n",
    "rating_matrix.fill(np.nan)\n",
    "def func(x):\n",
    "    rating_matrix[x[0],x[1]] = x[2]\n",
    "\n",
    "df.apply(func,axis = 1)\n",
    "\n",
    "print(rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NA in the matrix: 95.81 %\n",
      "Percentage of 1 in the matrix: 0.24 %\n",
      "Percentage of 2 in the matrix: 0.45 %\n",
      "Percentage of 3 in the matrix: 1.09 %\n",
      "Percentage of 4 in the matrix: 1.46 %\n",
      "Percentage of 5 in the matrix: 0.95 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of NA in the matrix:\",round((np.isnan(rating_matrix).sum()/rating_matrix.size)*100,2),\"%\")\n",
    "for i in range(1,6):\n",
    "    print(\"Percentage of\",i,\"in the matrix:\",round(((rating_matrix==i).sum()/rating_matrix.size)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix is very sparse, because obviously most users have only watched and rated a minor part of all the referenced movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of movies rated by user: 165.6\n",
      "Average rating: 3.58\n",
      "Minimum number of movies rated by a user: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of movies rated by user:\",round((~np.isnan(rating_matrix)).sum(1).mean(),2))\n",
    "print(\"Average rating:\",round(np.nanmean(rating_matrix),2))\n",
    "print(\"Minimum number of movies rated by a user:\", (~np.isnan(rating_matrix)).sum(1).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec2\"></a> 2. Building a recommender system\n",
    "\n",
    "## <a id=\"sec2-1\"></a> 2.1 Nearest Neighborhood algorithm\n",
    "\n",
    "The standard method of Collaborative Filtering is known as Nearest Neighborhood algorithm. There are two approaches: user-based or item-based. Here we will consider User-based Collaborative Filtering.\n",
    "<br><br>\n",
    "<img src=\"img/collaborative_filtering.png\" width=\"500px\">\n",
    "<i>Source: <a>https://dzone.com/articles/recommendation-engine-models\n",
    "</a></i>\n",
    "<br><br>\n",
    "We have an n × m matrix of ratings, with user uᵢ, i = 1, ...n and item pⱼ, j=1, …m. Now we want to predict the rating rᵢⱼ if target user i did not watch/rate an item j. The process is to calculate the similarities between target user i and all other users, select the top k similar users, and take the weighted average of ratings from these k users with similarities as weights.\n",
    "<br><br>\n",
    "$$r_{ij} = \\frac{\\sum_{k} similarity(u_i,u_k)r_{kj}}{\\sum_{k} similarity(u_i,u_k)}$$\n",
    "<br><br>\n",
    "While different people may have different baselines when giving ratings, some people tend to give high scores generally, some are pretty strict even though they are satisfied with items. To avoid this bias, we can subtract each user’s average rating of all items when computing weighted average, and add it back for target user, shown as below.\n",
    "<br><br>\n",
    "$$r_{ij} = \\bar{r_i} + \\frac{\\sum_{k} similarity(u_i,u_k)(r_{kj}-\\bar{r_{k}})}{\\sum_{k} |similarity(u_i,u_k)|}$$\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sec2-2\"></a> 2.2 Similarity metrics\n",
    "\n",
    "Each user is considered as a incomplete vector of which we only know a few components. Nevertheless we can compute a similarity value between a pair of users by only considering the ratings shared by both users.\n",
    "\n",
    "There are multiple similarity functions that can be used to render the closeness between two vectors. <br><br>\n",
    "Here we will consider two metrics:\n",
    "- The Cosine similarity: $$Sim(u_i,u_k) = \\frac{\\sum_j r_{ij}r_{kj}}{\\sqrt{\\sum_j r_{ij}^2 \\sum_j r_{kj}^2}}$$\n",
    "- The Pearson Correlation: $$Sim(u_i,u_k) = \\frac{\\sum_j (r_{ij}-\\bar{r_i})(r_{kj}-\\bar{r_k})}{\\sqrt{\\sum_j (r_{ij}-\\bar{r_i})^2 \\sum_j (r_{kj}-\\bar{r_k})^2}}$$\n",
    "\n",
    "<br><br>\n",
    "An implementation of these functions is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable tool code\n",
    "\n",
    "def pearson_similarity(u1,u2,target_item=None):\n",
    "    \n",
    "    # If an item is specified, remove it from the ratings vectors\n",
    "    if target_item != None:\n",
    "        u1 = np.delete(u1,target_item)\n",
    "        u2 = np.delete(u2,target_item)\n",
    "        \n",
    "    # Identify the movies rated by both users\n",
    "    common_ratings = np.logical_and(~np.isnan(u1), ~np.isnan(u2))\n",
    "\n",
    "    u1 = u1[common_ratings]\n",
    "    u2 = u2[common_ratings]\n",
    "    u1 -= u1.mean()\n",
    "    u2 -= u2.mean()\n",
    "    \n",
    "    res = ((u1**2).sum() * (u2**2).sum())\n",
    "    \n",
    "    # If no shared rating is found, the function returns 0\n",
    "    if res==0:\n",
    "        return 0\n",
    "    return (u1*u2).sum() / (res)**(1/2)\n",
    "    \n",
    "\n",
    "def cosine_similarity(u1,u2,target_item=None):\n",
    "    \n",
    "    # If an item is specified, remove it from the ratings vectors\n",
    "    if target_item != None:\n",
    "        u1 = np.delete(u1,target_item)\n",
    "        u2 = np.delete(u2,target_item)\n",
    "        \n",
    "    # Identify the movies rated by both users\n",
    "    common_ratings = np.logical_and(~np.isnan(u1), ~np.isnan(u2))\n",
    "\n",
    "    u1 = u1[common_ratings]\n",
    "    u2 = u2[common_ratings]\n",
    "\n",
    "    # If no shared rating is found, the function returns 0\n",
    "    res = ((u1**2).sum() * (u2**2).sum())\n",
    "    if res==0:\n",
    "        return 0\n",
    "    return (u1*u2).sum() / (res)**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these similarity metrics, we can now predict user's ratings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice:**<br>\n",
    "Implement the function predicting the rating of an item by a user based on the top k most similar users' ratings.\n",
    "The parameters are as following:\n",
    "- user is the user's vector of rating, corresponding to his row in the rating matrix\n",
    "- train_set is the matrix of ratings used for comparison, thus not including the target user\n",
    "- item is the index of the movie to be predicted\n",
    "- similarity is the metric used (two values are allowed, 'pearson' or 'cosine')\n",
    "- k is the number of similar users to consider\n",
    "\n",
    "The function should return the rating directly as a float value.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/predict_rating.py\n",
    "# Uncomment the line above to load a correction to this exercise.\n",
    "\n",
    "# Reusable tool code\n",
    "\n",
    "def predict_rating(user,train_set,item,similarity='pearson',k=100):\n",
    "    \n",
    "    mean_rating = np.nanmean(np.delete(user,item))\n",
    "    \n",
    "    similarities = []\n",
    "    if similarity == 'pearson':\n",
    "        similarities = [(u,pearson_similarity(user,train_set[u,:],target_item=item)) for u in range(train_set.shape[0])]\n",
    "    if similarity == 'cosine':\n",
    "        similarities = [(u,cosine_similarity(user,train_set[u,:],target_item=item)) for u in range(train_set.shape[0])]\n",
    "        \n",
    "    similarities = sorted(similarities, key=lambda x: x[1],reverse=True)[:k]\n",
    "\n",
    "    sum_similarities = 0\n",
    "    pred = 0\n",
    "    for u,s in similarities:\n",
    "        rating = train_set[u,item]\n",
    "        if ~np.isnan(rating):\n",
    "            pred += (rating - np.nanmean(train_set[u,:])) * s\n",
    "            sum_similarities += s\n",
    "    \n",
    "    if sum_similarities != 0:\n",
    "        pred /= sum_similarities\n",
    "    \n",
    "    return pred+mean_rating\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Try your function using the cell below and see how different your prediction is from the true rating.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating: 2.660832140941065\n",
      "Real rating: 2.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted rating:\",predict_rating(rating_matrix[654,:],np.delete(rating_matrix,654,0),item=3947,k=20))\n",
    "print(\"Real rating:\",rating_matrix[654,3947])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of the parameter k can sensibly affect the results: if k is too small then the most similar users picked will probably not have rated the target item, and if k is too big then all the less similar users considered will add noise to the result and will lower the model's precidion. The optimal value of k specific to the dataset, however Herlocker et al. found <b>k=20</b> to be a good starting value in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model turns out to be very unefficient, as we can see by computing the time needed to output a single prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.13860564709999607 s\n"
     ]
    }
   ],
   "source": [
    "pred_time = timeit.timeit('predict_rating(rating_matrix[654,:],np.delete(rating_matrix,654,0),16,1000)', number=10, globals=globals())/10\n",
    "print(\"Execution time:\",pred_time,\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two problems with our approach which explains this complexity:\n",
    "- Comparing two users is expensive as they each have thousands of attributes,\n",
    "- Finding top k similar users requires comparing the target user to every other.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the model we can use the Mean Average Error (MAE), but various other metrics are used.<br><br>\n",
    "$$MAE = \\frac{1}{n_un_i}\\sum_{u,i}e(u,i)$$\n",
    "with the following error function: \n",
    "$$e(u,i) = |pred(u,i) - x_{ui}|$$\n",
    "\n",
    "In this case, due to the amount of time needed to compute the error, we are not able to evaluate the whole system.\n",
    "Nevertheless, we can still try and compare our two metrics on a single test user using the error function defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes a few minutes to run\n",
    "\n",
    "test_user = 33\n",
    "rated_movies = np.where(~np.isnan(rating_matrix[test_user,:]))[0]\n",
    "train_set = np.delete(rating_matrix,test_user,0)\n",
    "\n",
    "true_ratings = rating_matrix[test_user,rated_movies]\n",
    "pred_ratings_pearson = [predict_rating(user=rating_matrix[test_user,:],item=m,similarity='pearson',train_set=train_set,k=100) for m in rated_movies]\n",
    "pred_ratings_cosine = [predict_rating(user=rating_matrix[test_user,:],item=m,similarity='cosine',train_set=train_set,k=100) for m in rated_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with Pearson similarity: 145.33615507214182\n",
      "Error with cosine similarity: 143.74130914160054\n"
     ]
    }
   ],
   "source": [
    "print(\"Error with Pearson similarity:\",np.absolute(pred_ratings_pearson-true_ratings).sum())\n",
    "print(\"Error with cosine similarity:\",np.absolute(pred_ratings_cosine-true_ratings).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first sight, the two similarity metrics seem sensibly equivalent.\n",
    "\n",
    "Actually, in 1998 John S. Breese and al. found empirically in <i>Empirical Analysis of Predictive Algorithms for Collaborative Filtering</i> [BHK98] that the best similarity metric for collaborative filtering was <b>Pearson correlation to the power 2.5</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec3\"></a> 3. Improving the model\n",
    "<br><br>\n",
    "The collaborative filtering approach suffers mainly from scarcity and scalability issues.\n",
    "In order to improve the system's efficiency, a natural approach is dimensionality reduction. The idea is to map the information contained in the rating matrix into a smaller matrix, which would be easier to process. Such a matrix can be obtained using Singular Value Decomposition (SVD). Following this analytical method, any matrix of size n x m can be decomposed as a product of three matrices of sizes <i>n x k</i>, <i>k x k</i>, and <i>k x m</i>.\n",
    "<br><br>\n",
    "<img src=\"img/singular_value_decomposition.png\" width=\"500px\">\n",
    "<br><br>\n",
    "This decomposition can be easily obtained with a dense matrix, however in our case the result matrices are not defined due to the missing values in our matrix.\n",
    "Although methods exist to fill the matrix with placeholder values in order to obtain a dense matrix (for example by replacing missing values with the user's average rating), some information is lost in the process because missing ratings are part of users' behavior and also convey information.\n",
    "<br><br>\n",
    "Therefore, we choose to use a different method which can be applied to sparce matrices, exploiting the fact that ratings are positive values: Non-negative Matrix Factorization.\n",
    "<br><br>\n",
    "## <a id=\"sec3-1\"></a> 3.1. Non-negative Matrix Factorization\n",
    "<br>\n",
    "Instead of factorizing our matrix R via SVD, we are trying to find two matrices P and Q directly with the goal that when P and Q are multiplied back together the output matrix R’ is the closest approximation of R and no longer a sparse matrix.\n",
    "<br><br>\n",
    "<img src=\"img/nmf.png\" width=\"500px\">\n",
    "<i>Source: <a>https://towardsdatascience.com/paper-summary-matrix-factorization-techniques-for-recommender-systems-82d1a7ace74\n",
    "</a></i>\n",
    "<br><br>\n",
    "For each component of the reconstructed matrix, we compute the error as follows:\n",
    "$$e_{ij}^2 = (r_{ij} - \\sum_k p_{ik}q_{kj})^2 + \\frac{\\beta}{2}\\sum_k (||P||^2+||Q||^2)$$\n",
    "where the second term is a regularization term added to avoid overfitting.\n",
    "\n",
    "To update P and Q, we can use a simple gradient descent algorithm. The gradient is approximated in the first order and the components are updated as follows:\n",
    "\n",
    "$$p_{ik}' = p_{ik} + \\alpha\\frac{\\partial}{\\partial p_{ik}}e_{ij}^2 = p_{ik} + \\alpha(2e_{ij}q_{kj} - \\beta p_{ik})$$\n",
    "$$q_{kj}' = q_{kj} + \\alpha\\frac{\\partial}{\\partial q_{kj}}e_{ij}^2 = q_{kj} + \\alpha(2e_{ij}p_{ik} - \\beta q_{kj})$$\n",
    "\n",
    "From there, we can build a very simple model which can be used to factorize our matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable tool code\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=5, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        print(\"Epoch\",step)\n",
    "        for i in range(len(R)):\n",
    "            if i%100==0:\n",
    "                print(round((i/len(R))*50,2),\"%\",end=\"\\r\")\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] != np.nan:\n",
    "                    if R[i][j] > 0:\n",
    "                        eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                        for k in range(K):\n",
    "                            P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                            Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        #eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in range(len(R)):\n",
    "            if i%100==0:\n",
    "                print(round(((i/len(R))*50)+50,2),\"%\",end=\"\\r\")\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] != np.nan:\n",
    "                    if R[i][j] > 0:\n",
    "                        e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                        for k in range(K):\n",
    "                            e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        print(\"Error:\",e)\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model. This step can take around five minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Error: 5774759.930196543\n",
      "Epoch 1\n",
      "Error: 3207828.3443274414\n",
      "Epoch 2\n",
      "Error: 2295127.4652669285\n",
      "Epoch 3\n",
      "Error: 1846720.89382152\n",
      "Epoch 4\n",
      "Error: 1588530.68833736\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "R = rating_matrix\n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    "\n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(M,K)\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sec3-2\"></a> 3.2. A working recommender system\n",
    "\n",
    "<br>\n",
    "The matrices computed can now be used to produce recommendations for users. We simply have to select the best predicted ratings among movies which were not already rated by the user. These will constitute our recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice:**<br>\n",
    "Implement a function that produces a list of k films' titles recommended to the user using the previously computed matrices.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/recommend.py\n",
    "# Uncomment the line above to load a correction to this exercise.\n",
    "\n",
    "# Reusable tool code\n",
    "\n",
    "def recommend(user,P,Q,k=10):\n",
    "    rated_movies = np.where(~np.isnan(rating_matrix[user,:]))[0]\n",
    "    pred_ratings = [[m,np.dot(nP[user,:],nQ.T[:,m])] for m in range(Q.shape[0]) if m not in rated_movies]\n",
    "    top_ratings = sorted(pred_ratings, key = lambda x: x[1], reverse=True)[:k]\n",
    "    \n",
    "    return [df_movies[df_movies[\"movie_id\"] == m[0]][\"title\"].values[0] for m in top_ratings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Try your function using the cell below and see what movies your recommender system pulls out.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Godfather, The (1972)',\n",
       " \"Schindler's List (1993)\",\n",
       " 'Star Wars: Episode IV - A New Hope (1977)',\n",
       " 'Raiders of the Lost Ark (1981)',\n",
       " 'Casablanca (1942)',\n",
       " \"One Flew Over the Cuckoo's Nest (1975)\",\n",
       " 'Usual Suspects, The (1995)',\n",
       " 'Sixth Sense, The (1999)',\n",
       " 'Silence of the Lambs, The (1991)',\n",
       " 'Saving Private Ryan (1998)']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user = 33\n",
    "\n",
    "recommend(test_user,nP,nQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model above is far more efficient than the initial one in terms of execution time. It is able to make fast (less than one second) recommendations and thus can be used online, where users do not generally accept to wait more than a few seconds to get a result.\n",
    "<br><br>\n",
    "Obviously, the matrix factorization affects the precision of the model but it is nevertheless justified by the major increase in terms of recommendation speed.\n",
    "<br><br>\n",
    "From there, in order to increase the recommendation power of this model, the matrix factorization algorithm could be trained longer, with a higher factorization order and parameters could be tuned so the output better encapsulates the information from the ratings matrix. We could also consider using some additional information on users and movies in order to compute clusters which would help make the recommender system even more performant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Collaborative filtering offers an efficient recommendation capacity, and presents the major advantage to require no external information on users or items apart from previous ratings.\n",
    "However it shows a few limitations:\n",
    "- The latent features mapped by the model cannot be easily interpreted, as could be the genre of a movie for instance.\n",
    "- It suffers from a \"cold start\": when a new user appears, the system is not able to produce good recommendations until a minimum number of ratings have been made.\n",
    "\n",
    "In practice, a good approach would be to complete a collaborative filtering model with features extracted from user and items information, thus using a more content-based approach. Overall, the main objective remains to find a good tradeoff between computational complexity and precision of recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>References & ressources</u>\n",
    "\n",
    "- Movielens dataset (1M) available at: <a>https://grouplens.org/datasets/movielens/</a>\n",
    "- https://www.lri.fr/~antoine/Courses/Master-ISI/section-app-collaboratif.pdf\n",
    "- Empirical Analysis of Predictive Algorithms for Collaborative Filtering [BHK98] (https://arxiv.org/pdf/1301.7363.pdf)\n",
    "- http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf\n",
    "- https://towardsdatascience.com/paper-summary-matrix-factorization-techniques-for-recommender-systems-82d1a7ace74\n",
    "- http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/#source-code\n",
    "- B. Dahlen, J. Konstan, J. Herlocker, N. Good, A. Borchers, and J. Riedl, “Jump-starting MovieLens: User benefits of starting a collaborative filtering system with ‘dead data,” Technical Report 98-017, University of Minnesota, Minneapolis, MN, March, 1998.\n",
    "- http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/#source-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
